import DocCard from '@site/src/components/DocCard';

# Reference

This page contains a succinct but precise definition of different concepts of Windmill.

## Scripts

In Windmill, a Script can be written in the following languages:
[TypeScript (Deno)](../getting_started/0_scripts_quickstart/1_typescript_quickstart/index.md),
[Python](../getting_started/0_scripts_quickstart/2_python_quickstart/index.md),
[Go](../getting_started/0_scripts_quickstart/3_go_quickstart/index.md),
[Bash](../getting_started/0_scripts_quickstart/4_bash_quickstart/index.md) or
[SQL](../getting_started/0_scripts_quickstart/5_sql_quickstart/index.md). Its
two most important components are the input [JSON Schema](../core_concepts/13_json_schema_and_parsing/index.md)
specification and the code content. Python and Go Scripts also have an
auto-genreated lockfile that ensure that executions of the same Script always
use the exact same set of versioned dependencies. The code must always have a
main function, which is its entrypoint when executed as an individual serverless
endpoint or a [Flow](../flows/1_flow_editor.mdx) module:

- TypeScript:

  ```typescript
  async function main(param1: string, param2: { nested: string }) {
  	...
  }
  ```

- Python:

  ```python
  def main(param1: str, param2: dict, ...):
  	...
  ```

- Go

  ```go
  func main(x string, nested struct{ Foo string \`json:"foo"\` }) (interface{}, error) {
  	...
  }
  ```

<div class="grid grid-cols-2 gap-6 mb-4">
	<DocCard
		title="Scripts Quickstart"
		description="Start writing scripts in Python, TypeScript, Go, Bash and Sql."
		href="/docs/getting_started/scripts_quickstart"
	/>
</div>

### Script kinds

You can attach additional functionalities to Scripts by specializing them into
specific Script kinds.

#### Actions

Actions - or Common Scripts - are the basic building blocks for the flows.

<div class="grid grid-cols-2 gap-6 mb-4">
  <DocCard
		title="Scripts Quickstart"
		description="Start writing scripts in Python, TypeScript, Go, Bash and Sql."
		href="/docs/getting_started/scripts_quickstart"
	/>
  <DocCard
		title="Flows Quickstart"
		description="Learn how to build flows."
		href="/docs/getting_started/flows_quickstart"
	/>
</div>

#### Trigger Scripts

These are used as the first step in Flows, most commonly with an internal
[state](#states) and a schedule to watch for changes on a
external system, and compare it to the previously saved state. If there are
changes,it _triggers_ the rest of the flow, i.e. subsequent Scripts.

<div class="grid grid-cols-2 gap-6 mb-4">
  <DocCard
		title="Trigger Scripts"
		description="Triggers are special actions that run periodically given a schedule."
		href="/docs/flows/flow_trigger"
	/>
  <DocCard
		title="Scheduling"
		description="Windmill provides the same set of features as CRON, but with a user interface and control panels."
		href="/docs/core_concepts/scheduling"
	/>
</div>

#### Approval Scripts

Suspend a flow until it's approved. An Approval Script will interact with the
Windmill API using any of the Windmill clients to retrieve a secret approval URL
and resume/cancel endpoints. Most common scenario for Approval Scripts is to
send an external notification with an URL that can be used to resume or cancel a
flow. For more details check
[Suspend and Resume tutorial](../flows/11_flow_approval.md).

<div class="grid grid-cols-2 gap-6 mb-4">
  <DocCard
		title="Approval Steps in Flows"
		description="Flows can be suspended until resumed or cancelled event(s) are received."
		href="/docs/flows/flow_approval"
	/>
</div>

#### Error Handlers

Handle errors for Flows after all retries attempts have been exhausted. If it
does not return an exception itself, the Flow is considered to be "recovered"
and will have a success status. So in most cases, you will have to rethrow an
error to have it be listed as a failed flow.

<div class="grid grid-cols-2 gap-6 mb-4">
  <DocCard
		title="Error Handler"
		description="The error handler is a special flow step that is executed when an error occurs in the flow."
		href="/docs/flows/flow_error_handler"
	/>
</div>

### Script hashes

Versions of Scripts are uniquely defined by their hashes. They are an immutable
reference similar to a git commit SHA. See [Versioning](#versioning). Scripts also
have a path and many versions share the same path. When a script is saved at a path,
it creates a new hash which becomes the "HEAD" of the path, the previous "HEAD" is
archived (but still deployed forever).

When a script is saved, it is immediately deployed.

### Versioning

Scripts, when created, can have a parent script identified by its **hash**.
Indeed, scripts are never overwritten, they are instead subsumed by a child
script which corresponds to the new version of the parent script. This
guarantees traceability of every action done on the platform, including editing
scripts. It also enables versioning. Versioning is a good practice from software
engineering which everyone familiar with git already knows. Windmill versioning
is a **simplified git** with two simplifying assumptions:

- **Linearity**: the lineage or the chain of Scripts from the one with no
  ancestor/parent to the one with no child is linear - there is no branching and
  there is no merging.
- **Not diff-based**: every versions of a Script contains its entire content and
  not just the diff between him and his direct parent. This is for simplicity
  and read-performance sake.

### Python client

By authenticating with the [reserved variable](../core_concepts/2_variables_and_secrets/index.md#contextual-variables)
`WM_TOKEN`, the Python client can interact with the Windmill platform from
within the script jobs. This can be used, for instance, to:

- Get Resources
- Run Scripts now and read their result synchronously
- Schedule a Script for later

The Python client can be used in any Script by using the following prelude:

```python
import wmill

def main(...):
  wmill.get_resource('my_resource_path')
```

### TypeScript (Deno) client

Similarly for TypeScript (Deno):

```typescript
import * as wmill from 'https://deno.land/x/windmill/index.ts'

async function main(...) {
  let x = await wmill.getResource('u/user/name')
}
```

### Custom Environment Variables

In a self-hosted environment, Windmill allows you to set custom environment variables for your scripts. This feature is useful when a script needs an environment variable prior to the main function executing itself. For instance, some libraries in Go do some setup in the 'init' function that depends on environment variables.

To add a custom environment variable to a script in Windmill, you should follow this format: `<KEY>=<VALUE>`. Where `<KEY>` is the name of the environment variable and `<VALUE>` is the corresponding value of the environment variable.

#### Request headers

It is possible for jobs to take request headers as arguments. To do so, either specify in the query args the headers to process at `include_headers`, separated with `,`. e.g: `/api/w/admins/jobs/run_wait_result/p/u/user/undisputed_script?include_header=X-Sign,foo`

or use the env variable: `INCLUDE_HEADERS` with the same format so that all requests to any job will include the headers.

#### Raw payload

Similarly to request headers, if the query args contain `raw=true`, then an additional argument will be added: `raw_string` which contains the entire json payload as a string (without any parsing). This is useful to verify the signature of the payload for example (discord require the endpoints to verify the signature for instance).

### Custom response code

For all sync run jobs endpoints, if the response contains a key `windmill_status_code` with a number value, that value will be used as the status code.
e.g: `{"windmill_status_code": 201}`

### SQL

For steps and scripts that use SQL, you can leverage the Windmill's `Sql` type
to display a monaco editor with SQL support in place of the normal `textarea`.
This allows for the entire query to be passed on as a parameter. For Flows, you
can still templatize the SQL query as you would for any Script.

![SQL](./sql.png)

<div class="grid grid-cols-2 gap-6 mb-4">
  <DocCard
		title="SQL Quickstart"
		description="Learn how to write SQL scripts in Windmill"
		href="/docs/getting_started/scripts_quickstart/sql"
	/>
</div>

## Handling Files and Binary Data

In Windmill, JSON is the primary data format used for representing information.
When working with binary data, such as files, they are represented as Base64 encoded strings.
Those Base64 strings can not be distinguished from normal strings.
Hence, the interpretation those Base64 encoded strings it either done depending on the context,
or by pre-fixing those strings with the [`<data specifier:>`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types).

In explicit contexts, when the JSON schema specifies that a property represents Base64-encoded data:

```
foo:
    type: string
    format: base64
```

If necessary, Windmill automatically converts it to the corresponding binary type in the corresping
language as defined in the schema.
In python, it will be converted to the `bytes` type. In Typescript, they are simply represented as strings.

In ambiguous situations (file ino) where the context does not provide clear indications,
it is necessary to precede the binary data with the `data:base64` [encoding declaration](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/Data_URLs).

In the app editor, in some cases when there is no ambiguity, the data prefix is optional.

Base64 encoded strings are used in:
- File Input component in the app editor: files uploaded are converted and returned as a Base64 encoded string.
- Download Button: the source to be downloaded must be in Base64 format.
- File inputs to run scripts must be typed into the [JSON](../core_concepts/13_json_schema_and_parsing/index.md) `string, encodingFormat: base64` (python: `bytes`, Deno: `wmill.Base64`).

<div class="grid grid-cols-2 gap-6 mb-4">
  <DocCard
		title="File Input Component"
		description="The file input allows users to drop files into the app."
		href="/docs/apps/app_configuration-settings/app_component_library#file-input"
	/>
  <DocCard
		title="Download Button"
		description="The download button component allows you to download a file."
		href="/docs/apps/app_configuration-settings/app_component_library#download-button"
	/>
  <DocCard
		title="JSON Schema and Parsing"
		description="JSON Schema is a key component in Windmill for defining and validating the structure and constraints of JSON data."
		href="/docs/core_concepts/json_schema_and_parsing"
	/>
</div>

## Rich display rendering

The result renderer will by default render results as a pretty JSON. However,
there are some cases that are handled specifically, so-called "rich results".
They are based on the format of the result.

This feature is useful if you want to display an image, a gif or a file instead of the the JSON of it.

If the result is an object/dict with a single key (except for `approval`, which
needs 3), you can leverage the following rich results:

| Type      | Description                                                 | Example (Deno)                                                                                                       |
| --------- | ----------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------- |
| json      | Render the value as a JSON                                  | `return { 'json': { 'a': 1 } }`                                                                                      |
| table-col | Render the value as a column in a table                     | `return { 'table-col': { 'foo': [42, 8], 'bar': [38, 12] }}`                                                         |
| table-row | Render the value as a row in a table                        | `return { 'table-row': [ 'foo', 'bar' ]}`                                                                            |
| html      | Render the value as HTML                                    | `return { 'html': '<div>...</div>' }`                                                                                |
| png       | Render the value as a PNG image                             | `return { 'png': encode(image) }`                                                                                    |
| file      | Render an option to download the file                       | `return { 'file': encode(file) }`                                                                                    |
| jpeg      | Render the value as a JPEG image                            | `return { 'jpeg': encode(image) }`                                                                                   |
| gif       | Render the value as a GIF image                             | `return { 'gif': encode(image) }`                                                                                    |
| error     | Render the value as an error message                        | `return { 'error': { 'name': '418', 'message': "I'm a teapot" }}`                                                    |
| approval  | Render an approval and buttons to Resume or Cancel the step | `return { 'resume': 'https://example.com', 'cancel': 'https://example.com', 'approvalPage': 'https://example.com' }` |
| svg       | Render the value as an SVG image                            | `return { 'svg': '<svg>...</svg>' }`                                                                                 |

**Regarding the tables:** If the result is a list whose first element is also a
list, it will display the result as a table. If the result is a dict/object
where every value is an array, it will also be displayed as a table, with the
key as the column name.

For example

```ts
import { encode } from "https://deno.land/std@0.82.0/encoding/base64.ts";

export async function main() {
  const url = 'https://source.unsplash.com/featured/300x201'
  const resp = await fetch(url)
  const buff = await resp.arrayBuffer()
  const data = encode(buff)
  return {
    png: data
  }
}
```

![](./rich_display_render_example.png)


## Flows

A Flow is a core concept. It is a JSON serializable value in the
[OpenFlow](../openflow/index.md) format that consists of an input spec (similar
to Scripts), and a linear sequence of steps, also referred to as modules.

For more details, please refer to the [flows section](../flows/1_flow_editor.mdx) or the [flows quickstart](../getting_started/6_flows_quickstart/index.md).

<div class="grid grid-cols-2 gap-6 mb-4">
  <DocCard
		title="Flows Quickstart"
		description="Learn how to build flows"
		href="/docs/getting_started/flows_quickstart."
	/>
  <DocCard
		title="Flow Editor"
		description="Dedicated section to Windmill's Flow Builder."
		href="/docs/flows/flow_editor"
	/>
  <DocCard
		title="OpenFlow Spec"
		description="OpenFlow is an open standard for defining Flows."
		href="/docs/openflow"
	/>
</div>

## Windmill Hub

The Windmill Hub at <https://hub.windmill.dev> is a community hub to ask for and
share generic task-specific Scripts, Flows, Apps and Resource Types that can be
reused by everyone who is using Windmill. Learn more about how you can use the
Hub in the [Share on Windmill Hub](../misc/1_share_on_hub/index.md) guide.

<div class="grid grid-cols-2 gap-6 mb-4">
  <DocCard
		title="Windmill Hub"
		description="Windmill's community platform"
		href="https://hub.windmill.dev/"
	/>
  <DocCard
		title="Share on Windmill Hub"
		description="Contribute and share to the Windmill community."
		href="/docs/misc/share_on_hub"
	/>
</div>

## Endpoints to trigger Scripts and Flows

The Script trigger URLs are always available on the Script details page.

![Script trigger hooks](./script_webhook.png)

For all of the REST endpoints, the input of the Script or Flow should be passed as a JSON payload that matches a JSON Schema spec that contains at least the input keys of that Script or Flow. However, if the payload contains extra keys that are not defined in the schema, they will be ignored, allowing you to work with arbitrary JSON payloads. Those endpoints are authenticated and will require a bearer token of the format: `Authorization: Bearer XXX`. You can create a token by clicking "Create token".

### Webhooks

Every Script or Flow can be run by its hash or path as a HTTP request aka as a
**Webhook**. You can find the webhook on the Script or Flow detail page but the
target URL follows this format (those are templates URL):

<!-- FIXME: Update URLs after merging #336 -->

- Flow by path:
  <a href="https://example.com" rel="nofollow">https://app.windmill.dev/api/w/$WORKSPACE_ID/jobs/run/f/$FLOW_PATH</a>

- Script by hash:
  <a href="https://example.com" rel="nofollow">https://app.windmill.dev/api/w/$WORKSPACE_ID/jobs/run/h/$SCRIPT_HASH</a>

- Script by path:
  <a href="https://example.com" rel="nofollow">https://app.windmill.dev/api/w/$WORKSPACE_ID/jobs/run/p/$SCRIPT_PATH</a>

Find more information on the [Webhooks section](/docs/core_concepts/webhooks/).

<div class="grid grid-cols-2 gap-6 mb-4">
  <DocCard
    	title="Webhooks"
    	description="Trigger scripts and flows from webhooks."
    	href="/docs/core_concepts/webhooks"
    />
</div>

### Synchronous endpoint for Scripts

aka "Lambda style" endpoints

Every script also exposes an endpoint that triggers the Script but waits for its
full execution before returning.

The endpoint has the following format:

```bash
https://app.windmill.dev/api/w/$WORKSPACE_ID/jobs/run_wait_result/$SCRIPT_PATH
```

where $SCRIPT_PATH is the path of the Script in the workspace, including the prefix `u/` or `f/`

## Jobs

A job represents a past, present or future "task" or "work" to be executed by a
[worker](#workers). Future jobs or jobs waiting for a worker are called "queued
jobs", and are ordered by the time at which they were scheduled for
(`scheduled_for`). Jobs that are created without being given a future
`scheduled_for` are [scheduled](../core_concepts/1_scheduling/index.md) for the time at which they were created.

[Workers](#workers) fetch jobs from the queue, start executing them, atomically
set their state in the queue to "running", stream the logs while executing them,
then once completed remove them from the queue and create a new "completed job".

Every job has a unique UUID attached to it and as long as you have visibility
over the execution of the script, you are able to inspect the execution logs,
output and metadata in the dedicated details page of the job.

### Job kinds

There are 5 main kinds of jobs, that each have a dedicated tab in the [runs page](../core_concepts/5_monitor_past_and_future_runs/index.mdx):

- **Script Jobs**: Run a script as defined by the hash of the script (that
  uniquely and immutably defines a specific version of a script), its input
  arguments (args) and the `permissioned_as` user or group of whom it is going to
  act on behalf of and inherit the visibility to other items such as resources
  and variables from. An user can **NEVER** escalates his privileges but only
  de-escalates it by launching a script with either the same permissions as
  himself or a subset of it (by giving the permissions of a group that he is
  member of).

- **Preview Jobs**: similar to script jobs but instead of hash, they contain the
  whole raw code they will run. Those are the jobs that are launched from the
  script editors. Even when code is executed as a preview, you keep a trace of
  its execution.

- **Dependencies Jobs**: Scripts written in Python generate a lock file when
  they are saved/created. This lockfile ensures that an execution of the same
  hash will always use the same versions. The process of generating this
  lockfile is also a job in itself so you can easily inspect the issues
  generating the lockfile if any. See
  [Dependency Management](../advanced/6_imports/index.md) for more information.

- **Flow Jobs**: A flow job is the "meta" job that orchestrates the execution of
  every step. The execution of the steps are in-themselves jobs. It is defined
  similarly to a script job but instead of being defined by a path to a script,
  it is defined by a path to the flow.

- **Preview Flow Jobs**: A preview flow is a job that contains the raw json
  definition of the flow instead of merely a path to it. It is the underlying
  job for the preview of flows in the flow editor interface.

### Run jobs on behalf of

The `permissioned_as` value from script and preview jobs is the most important
concept to grasp to understand what makes Windmill's security and permission
model consistent, predictable and safe. `permissioned_as` is distinct from the
`created_by` value, even though in the vast majority of jobs, they will be the
same. It represents the level of permissions this job will execute with. As a
direct consequence, the variables (including secrets) that are accessible to the
scripts are only those whom the user or group has visibility on, given his
[permissions](../core_concepts/16_roles_and_permissions/index.mdx).

Similarly for the [Contextual Variable](../core_concepts/2_variables_and_secrets/index.md#contextual-variables) `WM_TOKEN` which
contains an ephemeral token (ephemeral to the script execution), which has the
same privilege and permissions as the owner in `permissioned_as`. The
[Python client](#python-client) inside the script implicitly uses that same
token to be granted privilege to do Windmill operations (like running other
scripts or getting resources), meaning that the same script ran by 2 different
users, will run differently and may be unauthorized to do partially or all
operations of the script. This is what enables anyone to share scripts doing
sensitive operations safely as long as the resources and secrets that the script
relies on are permissioned correctly.

A user can only run a script permissioned as either himself, one of the group
that he is a member of.

### Job inputs and Script parameters

Jobs take a JSON object as input which can be empty. That input is passed as the payload of the POST request that triggers the Script. The different key-value pairs of the objects are passed as the different parameters of the main function, with just a few language-specific transformations to more adequate types in the target language, if necessary (e.g base64/datetime encoding). Values can be nested JSON objects themselves, but we recommend trying to keep the input flat when possible.

If the payload contains keys that are not defined as parameters in the main function, they will be ignored. This allows you to handle arbitrary JSON payloads, as you can choose which keys to define as parameters in your script and process the data accordingly.

## Workers

Workers are autonomous processes that run one script at a time using the full
machines resources available to them.

Workers pull [jobs](#jobs) from the queue of jobs in the order of their
`scheduled_for` datetime as long as it is in the past. As soon as a worker pulls
a job, it atomically sets its state to "running", runs it, streams its logs then
once it is complete, saves it back in the database as a "complete job". The
final result and logs are stored forever.

The number of workers can be horizontally scaled up or down depending on needs
without any overhead.

## Workspace

Every nameable or pathable entity in Windmill has a workspace attached to it.
This includes:

- users
- groups
- scripts
- resources
- variables
- schedules
- jobs

Windmill's entire database is partitioned by workspaces such that users, teams
and orgs can safely co-locate without risk of leakage.

Any user can create his own workspace. When a user creates a workspace, he is an
admin of such workspace and he can invite others to join his workspace.